{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 995, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 959, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: No loss found. You may have forgotten to provide a `loss` argument in the `compile()` method.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11468\\1755113889.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[1;31m# Train the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 86\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage_arr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmask_arr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     87\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m \u001B[1;31m# Once the model is trained, you can use it for inference on new images\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[1;31m# To get the full stack trace, call:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m             \u001B[1;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 70\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     71\u001B[0m         \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     72\u001B[0m             \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mtf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m                 \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m                     \u001B[0mdo_return\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m                     \u001B[0mretval_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconverted_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mld\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep_function\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mld\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mag__\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mld\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfscope\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m                 \u001B[1;32mexcept\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m                     \u001B[0mdo_return\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 995, in train_step\n        self._validate_target_and_loss(y, loss)\n    File \"C:\\Users\\alexd\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 959, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: No loss found. You may have forgotten to provide a `loss` argument in the `compile()` method.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import keras.losses\n",
    "\n",
    "# Define your model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(153, 153, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(tf.multiply(y_true, y_pred))\n",
    "    union = tf.reduce_sum(tf.subtract(tf.add(y_true, y_pred), tf.multiply(y_true, y_pred)))\n",
    "    iou_score = tf.divide(intersection, union)\n",
    "    return iou_score\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[iou])\n",
    "\n",
    "# Load and preprocess your data\n",
    "# Assuming you have images and corresponding masks in separate directories\n",
    "# You will need to modify this part based on your data directory structure\n",
    "image_dir = '../cse-seminar/small_images'\n",
    "mask_dir = '../cse-seminar/labeled_data'\n",
    "image_files = []  # List of image filenames\n",
    "mask_files = []  # List of mask filenames\n",
    "\n",
    "labeled_data  = []\n",
    "mask = []\n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "    # Check if the file has a common image extension (e.g., jpg, png, etc.)\n",
    "    if filename.lower().endswith('.png'):\n",
    "        # Construct the full file path by joining the folder path and filename\n",
    "        file_path =  filename\n",
    "        # Append the file path to the list of image paths\n",
    "        image_files.append(file_path)\n",
    "\n",
    "for filename in os.listdir(mask_dir):\n",
    "    # Check if the file has a common image extension (e.g., jpg, png, etc.)\n",
    "    if filename.lower().endswith('.npy'):\n",
    "        # Construct the full file path by joining the folder path and filename\n",
    "        file_path =  filename\n",
    "        # Append the file path to the list of image paths\n",
    "        mask_files.append(file_path)\n",
    "\n",
    "pattern = r\"task-(\\d+)-\"\n",
    "for i in range(0,len(labeled_data) - 1):\n",
    "    match = re.search(pattern, labeled_data[i])\n",
    "    result = int(re.sub(r\"task-|-\", \"\", match.group(0)),10)\n",
    "    mask[result - 1] = np.load(labeled_data[i])\n",
    "\n",
    "mask = np.expand_dims(mask,axis=0)\n",
    "print(mask)\n",
    "# Iterate over each image and mask\n",
    "for image_file, mask_file in zip(image_files, mask_files):\n",
    "    # Load the image and mask\n",
    "    image = Image.open(image_dir + '/' + image_file)\n",
    "    #mask = Image.open(mask_dir + '/' + mask_file).convert('L')\n",
    "\n",
    "    # Resize images if necessary\n",
    "    image = image.resize((153, 153))\n",
    "    #mask = mask.resize((153, 153))\n",
    "\n",
    "    # Convert the image and mask to numpy arrays\n",
    "    image_arr = keras.utils.img_to_array(image) / 255.0  # Normalize pixel values between 0 and 1\n",
    "    #mask_arr = keras.utils.img_to_array(mask) / 255.0  # Normalize pixel values between 0 and 1\n",
    "\n",
    "    # Expand dimensions to match input shape of the model\n",
    "    image_arr = np.expand_dims(image_arr, axis=0)\n",
    "    #mask_arr = np.expand_dims(mask_arr, axis=0)\n",
    "\n",
    "# Train the model\n",
    "model.fit(image_arr, mask_arr, batch_size=1, epochs=10)\n",
    "\n",
    "# Once the model is trained, you can use it for inference on new images\n",
    "# Assuming you have a new image for segmentation\n",
    "new_image_file = '../cse-seminar/small_images/small_image1.png'\n",
    "new_image = keras.utils.image.load_img(new_image_file, target_size=(153, 153))\n",
    "new_image_arr = keras.utils.image.img_to_array(new_image) / 255.0  # Normalize pixel values between 0 and 1\n",
    "new_image_arr = np.expand_dims(new_image_arr, axis=0)\n",
    "\n",
    "# Perform inference\n",
    "predicted_mask = model.predict(new_image_arr)\n",
    "\n",
    "# Convert predicted mask to image format for visualization or further processing\n",
    "predicted_mask = (predicted_mask[0] > 0.5).astype(np.uint8) * 255\n",
    "predicted_mask_img = keras.utils.image.array_to_img(predicted_mask)\n",
    "\n",
    "# Save the predicted mask image\n",
    "#predicted_mask_img.save('path/to/save/predicted_mask.jpg')\n",
    "plt.imshow(predicted_mask_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
